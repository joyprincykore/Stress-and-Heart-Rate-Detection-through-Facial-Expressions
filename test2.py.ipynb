{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812a343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "#from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from scipy.spatial import distance as dist\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class VideoCamera(object):\n",
    "    def __init__(cap):\n",
    "        #real time video capture\n",
    "        cap.video = cv2.VideoCapture(0)\n",
    "    def __del__(cap):\n",
    "        cap.video.release()\n",
    "        \n",
    "    def get_frame(cap):\n",
    "    #    while(True):    \n",
    "        ret,frame = cap.video.read()\n",
    "        frame = cv2.flip(frame,1)\n",
    "        frame = imutils.resize(frame, width=500,height=500)\n",
    "        #gettting points of eye from the facial landmark\n",
    "        (lBegin, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"]\n",
    "        (rBegin, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"]\n",
    "        # getting lip points from facial landmarks\n",
    "        (l_lower, l_upper) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "        #preprocessing the image\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        detections = detector(gray,0)\n",
    "        for detection in detections:\n",
    "            emotion= emotion_finder(detection,gray)\n",
    "            cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            shape = predictor(frame,detection)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "               \n",
    "            leyebrow = shape[lBegin:lEnd]\n",
    "            reyebrow = shape[rBegin:rEnd]\n",
    "            openmouth = shape[l_lower:l_upper]\n",
    "            # figuring out convex shape \n",
    "            reyebrowhull = cv2.convexHull(reyebrow)\n",
    "            leyebrowhull = cv2.convexHull(leyebrow)\n",
    "            openmouthhull = cv2.convexHull(openmouth) \n",
    "    \n",
    "            cv2.drawContours(frame, [reyebrowhull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [leyebrowhull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [openmouthhull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Measuring lip distance and eye distance\n",
    "            lipdist = lpdist(openmouthhull[-1],openmouthhull[0])\n",
    "            eyedist = ebdist(leyebrow[-1],reyebrow[0])\n",
    "    \n",
    "            stress_value,stress_label = normalize_values(points,eyedist, points_lip, lipdist)\n",
    "            #displaying stress levels and value \n",
    "            cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (235, 52, 52), 2)\n",
    "            cv2.putText(frame,\"stress value:{}\".format(str(int(stress_value*100))),(10,40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (51, 66, 232), 2)\n",
    "            cv2.putText(frame,\"Stress level:{}\".format((stress_label)),(10,60),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (35, 189, 25), 2)\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "        ret, jpeg = cv2.imencode('.jpg', frame)\n",
    "        return jpeg.tobytes()\n",
    "    def plt_show():\n",
    "        plot_stress=plt.plot(range(len(points)),points,'ro')\n",
    "        plt.title(\"Stress Levels\")\n",
    "        plt.show()\n",
    "        return plot_stress\n",
    "\n",
    "\n",
    "\n",
    "global points, points_lip, emotion_classifier, detector, predictor\n",
    "\n",
    "#importing frontal facial landmark detector        \n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "#loading the trained model\n",
    "emotion_classifier = load_model(\"_mini_XCEPTION.102-0.66.hdf5\", compile=False)\n",
    "cap = cv2.VideoCapture(0)\n",
    "points=[]; points_lip=[]\n",
    "    \n",
    "#calculating eye distance in terms of the facial landmark\n",
    "def ebdist(leye,reye):\n",
    "    eyedist = dist.euclidean(leye,reye)\n",
    "    points.append(int(eyedist))\n",
    "    return eyedist\n",
    "\n",
    "#calculating lip dostance using facial landmark\n",
    "def lpdist(l_lower,l_upper):\n",
    "    lipdist = dist.euclidean(l_lower, l_upper)\n",
    "    points_lip.append(int(lipdist))\n",
    "    return lipdist\n",
    "\n",
    "#finding stressed or not using the emotions \n",
    "def emotion_finder(faces,frame):\n",
    "    EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n",
    "    x,y,w,h = face_utils.rect_to_bb(faces)\n",
    "    frame = frame[y:y+h,x:x+w]\n",
    "    roi = cv2.resize(frame,(64,64))\n",
    "    roi = roi.astype(\"float\") / 255.0\n",
    "    roi = img_to_array(roi)\n",
    "    roi = np.expand_dims(roi,axis=0)\n",
    "    preds = emotion_classifier.predict(roi)[0]\n",
    "    emotion_probability = np.max(preds)\n",
    "    label = EMOTIONS[preds.argmax()]\n",
    "    if label in ['scared','sad','angry']:\n",
    "        label = 'Stressed'\n",
    "    else:\n",
    "        label = 'Not Stressed'\n",
    "    return label\n",
    "\n",
    "#calculating stress value using the distances\n",
    "def normalize_values(points,disp,points_lip,dis_lip):\n",
    "    normalize_value_lip = abs(dis_lip - np.min(points_lip))/abs(np.max(points_lip) - np.min(points_lip))\n",
    "    normalized_value_eye =abs(disp - np.min(points))/abs(np.max(points) - np.min(points))\n",
    "    normalized_value =( normalized_value_eye + normalize_value_lip)/2\n",
    "    stress_value = (np.exp(-(normalized_value)))\n",
    "    if stress_value>=0.65:\n",
    "        stress_label=\"High Stress\"\n",
    "    else:\n",
    "        stress_label=\"Low Stress\"\n",
    "    return stress_value,stress_label\n",
    " \n",
    "#processing real time video input to display stress \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a95ebb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086609d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
