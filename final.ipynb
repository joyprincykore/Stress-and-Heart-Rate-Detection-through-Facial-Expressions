{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0786998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "wb=Workbook()\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "from PIL import Image\n",
    "\n",
    "win=Tk()\n",
    "win.geometry(\"700x500\")\n",
    "Label(win,text=\"Stress Detection through Facial Expressions\",font=('Aerial 24 bold italic')).pack(pady=20)\n",
    "bg=Image.open(\"download.jpg\")\n",
    "photo=ImageTk.PhotoImage(bg,master=win)\n",
    "\n",
    "label1=Label(win,image=photo)\n",
    "label1.place(x=0,y=0,relwidth=1,relheight=1)\n",
    "label1.image=bg\n",
    "label1.pack()\n",
    "\n",
    "\n",
    "def show_img():\n",
    "    from scipy.spatial import distance as dist\n",
    "    from imutils.video import VideoStream\n",
    "    from imutils import face_utils\n",
    "    import numpy as np\n",
    "    import imutils\n",
    "    import time\n",
    "    import dlib\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "#from keras_preprocessing.image import img_to_array\n",
    "    from tensorflow.keras.utils import img_to_array\n",
    "    from keras.models import load_model\n",
    "\n",
    "# function to calculate heart rate\n",
    "    def calculate_heart_rate(color_signal, fps):\n",
    "        b, g, r = cv2.split(color_signal)\n",
    "        roi = g[150:350, 150:350]\n",
    "        mean_intensity = np.mean(roi)\n",
    "        heart_rate = mean_intensity * (60 * fps / 512)\n",
    "        return heart_rate/5\n",
    "\n",
    "    def ebdist(leye,reye):\n",
    "        eyedist = dist.euclidean(leye,reye)\n",
    "        points.append(int(eyedist))\n",
    "        return eyedist\n",
    "\n",
    "#calculating lip dostance using facial landmark\n",
    "    def lpdist(l_lower,l_upper):\n",
    "        lipdist = dist.euclidean(l_lower, l_upper)\n",
    "        points_lip.append(int(lipdist))\n",
    "        return lipdist\n",
    "\n",
    "#finding stressed or not using the emotions \n",
    "    def emotion_finder(faces,frame):\n",
    "        EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n",
    "        x,y,w,h = face_utils.rect_to_bb(faces)\n",
    "        frame = frame[y:y+h,x:x+w]\n",
    "        roi = cv2.resize(frame,(64,64))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi,axis=0)\n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "        if label in ['scared','sad','angry']:\n",
    "            label = 'Stressed'\n",
    "        else:\n",
    "            label = 'Not Stressed'\n",
    "        return label\n",
    "\n",
    "# function to calculate stress level based on heart rate and facial features\n",
    "    def calculate_stress(points, eyedist, points_lip, lipdist, heart_rate):\n",
    "    # normalize values\n",
    "        norm_eyedist = eyedist / np.max(points)\n",
    "        norm_lipdist = lipdist / np.max(points_lip)\n",
    "        norm_hr = (heart_rate - 50) / 150\n",
    "    # calculate stress value\n",
    "        stress_value = 0.6 * norm_eyedist + 0.3 * norm_lipdist + 0.1 * norm_hr\n",
    "    # calculate stress level based on stress value\n",
    "        if stress_value <= 0.33:\n",
    "            stress_label = \"Low\"\n",
    "        elif stress_value <= 0.66:\n",
    "            stress_label = \"Moderate\"\n",
    "        else:\n",
    "            stress_label = \"High\"\n",
    "        return stress_value, stress_label\n",
    "    global points, points_lip, emotion_classifier, detector, predictor\n",
    "\n",
    "    emotion_classifier = load_model(\"_mini_XCEPTION.102-0.66.hdf5\", compile=False)\n",
    "    points = []; points_lip=[]\n",
    "\n",
    "# initialize video stream\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "# load face detector and facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# initialize heart rate calculation variables\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    color_signal = None\n",
    "\n",
    "    while(True):    \n",
    "            ret,frame = cap.read()\n",
    "            frame = cv2.flip(frame,1)#to rotate img along x-axis and y-axis or both\n",
    "            frame = imutils.resize(frame, width=500,height=500)#imutils - for resizing,translation,rotation and displaying matplotlib imgs\n",
    "        #gettting points of eye from the facial landmark\n",
    "            (lBegin, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"]\n",
    "            (rBegin, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"]\n",
    "        # getting lip points from facial landmarks\n",
    "            (l_lower, l_upper) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "        #preprocessing the image\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "            detections = detector(gray,0)\n",
    "            for detection in detections:\n",
    "                emotion= emotion_finder(detection,gray)\n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)#to display emotion\n",
    "                shape = predictor(frame,detection)\n",
    "                shape = face_utils.shape_to_np(shape)#used to convert to numpy array which is used to easily detect the facial landmarks\n",
    "               \n",
    "                leyebrow = shape[lBegin:lEnd]\n",
    "                reyebrow = shape[rBegin:rEnd]\n",
    "                openmouth = shape[l_lower:l_upper]\n",
    "            # figuring out convex shape \n",
    "                reyebrowhull = cv2.convexHull(reyebrow) #eyebrow points are consdered as boundary and points inside form a cluster\n",
    "                leyebrowhull = cv2.convexHull(leyebrow) #A convex hull encloses a set of points and it acts as a cluster boundary which helps in determining all the points within a cluster.\n",
    "                openmouthhull = cv2.convexHull(openmouth) \n",
    "    \n",
    "                cv2.drawContours(frame, [reyebrowhull], -1, (0, 255, 0), 1) #the boundary color drawn around the eyebrow\n",
    "                cv2.drawContours(frame, [leyebrowhull], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(frame, [openmouthhull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Measuring lip distance and eye distance\n",
    "                \n",
    "                eyedist = ebdist(leyebrow[-1],reyebrow[0])\n",
    "                lipdist = lpdist(openmouth[-1],openmouth[0])\n",
    "                # calculate heart rate\n",
    "                fps=30\n",
    "                heart_rate = calculate_heart_rate(frame, fps) \n",
    "                \n",
    "                stress_value,stress_label = calculate_stress(points,eyedist, points_lip, lipdist,heart_rate)\n",
    "            #displaying stress levels and value \n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (235, 52, 52), 2)\n",
    "                cv2.putText(frame,\"stress value:{}\".format(str(int(stress_value*100))),(10,40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (51, 66, 232), 2)\n",
    "                cv2.putText(frame,\"Stress level:{}\".format((stress_label)),(10,60),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (35, 189, 25), 2)\n",
    "                cv2.putText(frame,\"Heart Rate: {} bpm\".format(int(heart_rate)), (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
    " \n",
    "            \n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "    def plt_show():\n",
    "        plot_stress=plt.plot(range(len(points)),points,'ro')\n",
    "        plt.title(\"Stress Levels\")\n",
    "        plt.show()\n",
    "        return plot_stress\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    plt.plot(range(len(points)),points,'ro')\n",
    "    plt.title(\"Stress Levels\")\n",
    "    plt.show()\n",
    "#Label(win,text=\"Stress Detection!\",font=('Aerial 17 bold italic')).pack(pady=20)\n",
    "tk.Button(win,bg=\"pink\",activebackground=\"pink\",font=\"arial 24\",text=\"Stress Detection\",borderwidth=10,command=show_img).pack(pady=20)\n",
    "Label(win,text=\"Tips to tame stress:\",font=('Aerial 20 bold italic')).pack(pady=10)\n",
    "def create_label(text):\n",
    "    label = tk.Label(win, text=text, wraplength=800, justify=\"left\",font=('Helvetica 12 bold'))\n",
    "    label.pack(pady=10)\n",
    "\n",
    "#canvas= Canvas(win, width= 1500, height= 750)\n",
    "create_label(\"Breaaatheeee!: Take slow, deep breaths to lower heart rate and blood pressure.\")\n",
    "create_label(\"Take a quick walk: When you’re feeling overwhelmed go for a quick stroll. You’ll get the benefits of alone time, physical activity, and a few minutes to gather your thoughts.\")\n",
    "create_label(\"Count Backward!: When worries are running rampant, try slowly counting to 10 and then back again to calm down.\")\n",
    "create_label(\"Stretch: Stand up for a quick stretch to relieve muscle tension which helps you relax.\")\n",
    "create_label(\"Write it down buddy: Putting our emotions on paper can make them seem less intimidating, hence try journaling to calm your nerves.\")\n",
    "create_label(\"Talk to a Friend: When something’s really bothering you, it can help to share your feelings with a buddy. Vent it out!!\")\n",
    "\n",
    "#Add a text in Canvas\n",
    "#canvas.create_text(text=\"1. Breaaatheeee!: Take slow, deep breaths to lower heart rate and blood pressure.\", fill=\"black\", font=('Helvetica 15 bold'),justify='center')\n",
    "#canvas.create_text(800, text=\"2. Take a quick walk: When you’re feeling overwhelmed go for a quick stroll. You’ll get the benefits of alone time, physical activity, and a\", fill=\"black\", font=('Helvetica 15 bold'),justify='center')\n",
    "#canvas.create_text(830, text=\"few minutes to gather your thoughts.\", fill=\"black\", font=('Helvetica 15 bold'),justify='center')\n",
    "\n",
    "                   #2. Take a quick walk: When you’re feeling overwhelmed go for a quick stroll. You’ll get the benefits of alone time, physical activity, and a few minutes to gather your thoughts.3. Count Backward!: When worries are running rampant, try slowly counting to 10 and then back again to calm down.4. Stretch: Stand up for a quick stretch to relieve muscle tension which helps you relax.5. Write it down buddy: Putting our emotions on paper can make them seem less intimidating, hence try journaling to calm your nerves.6. Talk to a Friend: When something’s really bothering you, it can help to share your feelings with a buddy. Vent it out!!\", fill=\"black\", font=('Helvetica 15 bold'),justify='center')\n",
    "\n",
    "#canvas.pack()\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd410ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\JOY' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ecd44dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlwt in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (1.3.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install xlwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84870635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-3-23c23684bc9d>\", line 51, in show_img\n",
      "    from tensorflow.keras.utils import img_to_array\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 45, in <module>\n",
      "    from tensorflow.python.feature_column import feature_column_lib as feature_column\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py\", line 18, in <module>\n",
      "    from tensorflow.python.feature_column.feature_column import *\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 143, in <module>\n",
      "    from tensorflow.python.layers import base\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 16, in <module>\n",
      "    from tensorflow.python.keras.legacy_tf_layers import base\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\", line 25, in <module>\n",
      "    from tensorflow.python.keras import models\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\", line 22, in <module>\n",
      "    from tensorflow.python.keras.engine import functional\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 32, in <module>\n",
      "    from tensorflow.python.keras.engine import training as training_lib\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 54, in <module>\n",
      "    from tensorflow.python.keras.saving import hdf5_format\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\", line 37, in <module>\n",
      "    import h5py\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\h5py\\__init__.py\", line 46, in <module>\n",
      "    from ._conv import register_converters as _register_converters\n",
      "  File \"h5py\\h5t.pxd\", line 14, in init h5py._conv\n",
      "  File \"h5py\\h5t.pyx\", line 293, in init h5py.h5t\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\numpy\\__init__.py\", line 320, in __getattr__\n",
      "    raise AttributeError(\"module {!r} has no attribute \"\n",
      "AttributeError: module 'numpy' has no attribute 'typeDict'\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "import webbrowser\n",
    "import statistics\n",
    "import html\n",
    "\n",
    "from datetime import datetime\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "wb=Workbook()\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "from PIL import Image\n",
    "\n",
    "win=Tk()\n",
    "win.geometry(\"700x500\")\n",
    "Label(win,bg='#f5e4ef',text=\"Stress Detection through Facial Expressions\",font=('Aerial 24 bold italic')).pack(pady=20)\n",
    "bg=Image.open(\"download.jpg\")\n",
    "photo=ImageTk.PhotoImage(bg,master=win)\n",
    "\n",
    "\n",
    "label1=Label(win,image=photo)\n",
    "label1.place(x=0,y=0,relwidth=1,relheight=1)\n",
    "label1.image=bg\n",
    "label1.pack()\n",
    "\n",
    "label = Label(win,bg=\"#f5e4ef\",borderwidth=3,font=('Aerial 20 bold italic'))\n",
    "label.pack()\n",
    "\n",
    "label2 = Label(win,bg=\"#f5e4ef\",borderwidth=3,font=('Aerial 20 bold italic'))\n",
    "label2.pack()\n",
    "\n",
    "stress_labels = []\n",
    "\n",
    "#average_stress_value=0\n",
    "def show_img():\n",
    "    from scipy.spatial import distance as dist\n",
    "    from imutils.video import VideoStream\n",
    "    from imutils import face_utils\n",
    "    import numpy as np\n",
    "    import imutils\n",
    "    import time\n",
    "    import dlib\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "#from keras_preprocessing.image import img_to_array\n",
    "    from tensorflow.keras.utils import img_to_array\n",
    "    from keras.models import load_model\n",
    "\n",
    "# function to calculate heart rate\n",
    "    def calculate_heart_rate(color_signal, fps):\n",
    "        b, g, r = cv2.split(color_signal)\n",
    "        roi = g[150:350, 150:350]\n",
    "        mean_intensity = np.mean(roi)\n",
    "        heart_rate = mean_intensity * (60 * fps / 512)\n",
    "        return heart_rate/5\n",
    "\n",
    "    def ebdist(leye,reye):\n",
    "        eyedist = dist.euclidean(leye,reye)\n",
    "        points.append(int(eyedist))\n",
    "        return eyedist\n",
    "\n",
    "#calculating lip dostance using facial landmark\n",
    "    def lpdist(l_lower,l_upper):\n",
    "        lipdist = dist.euclidean(l_lower, l_upper)\n",
    "        points_lip.append(int(lipdist))\n",
    "        return lipdist\n",
    "    emotions = []\n",
    "#finding stressed or not using the emotions \n",
    "    def emotion_finder(faces,frame):\n",
    "        EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n",
    "        x,y,w,h = face_utils.rect_to_bb(faces)\n",
    "        frame = frame[y:y+h,x:x+w]\n",
    "        roi = cv2.resize(frame,(64,64))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi,axis=0)\n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "        if label in ['scared','sad','angry']:\n",
    "            label = 'Stressed'\n",
    "        else:\n",
    "            label = 'Not Stressed'\n",
    "        \n",
    "        return label\n",
    "    stress_values = []\n",
    "    \n",
    "# function to calculate stress level based on heart rate and facial features\n",
    "    def calculate_stress(points, eyedist, points_lip, lipdist, heart_rate):\n",
    "    # normalize values\n",
    "        norm_eyedist = eyedist / np.max(points)\n",
    "        norm_lipdist = lipdist / np.max(points_lip)\n",
    "        norm_hr = (heart_rate - 50) / 150\n",
    "    # calculate stress value\n",
    "        stress_value = 0.6 * norm_eyedist + 0.3 * norm_lipdist + 0.1 * norm_hr\n",
    "        \n",
    "        stress_values.append(stress_value)\n",
    "        \n",
    "    # calculate stress level based on stress value\n",
    "        if stress_value <= 0.66:\n",
    "            stress_label = \"Low\"\n",
    "        elif stress_value <= 0.80:\n",
    "            stress_label = \"Moderate\"\n",
    "        else:\n",
    "            stress_label = \"High\"\n",
    "        return stress_value, stress_label\n",
    "    global points, points_lip, emotion_classifier, detector, predictor,average_stress_value\n",
    "\n",
    "    emotion_classifier = load_model(\"_mini_XCEPTION.102-0.66.hdf5\", compile=False)\n",
    "    points = []; points_lip=[]\n",
    "\n",
    "# initialize video stream\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "# load face detector and facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# initialize heart rate calculation variables\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    color_signal = None\n",
    "    \n",
    "    total_stress_value = 0\n",
    "    num_frames = 0\n",
    "    stress_label = \"\"\n",
    "    while(True):    \n",
    "            ret,frame = cap.read()\n",
    "            frame = cv2.flip(frame,1)#to rotate img along x-axis and y-axis or both\n",
    "            frame = imutils.resize(frame, width=500,height=500)#imutils - for resizing,translation,rotation and displaying matplotlib imgs\n",
    "        #gettting points of eye from the facial landmark\n",
    "            (lBegin, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"]\n",
    "            (rBegin, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"]\n",
    "        # getting lip points from facial landmarks\n",
    "            (l_lower, l_upper) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "        #preprocessing the image\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "            detections = detector(gray,0)\n",
    "            for detection in detections:\n",
    "                emotion= emotion_finder(detection,gray)\n",
    "                emotions.append(emotion)\n",
    "                #label2.config(text=emotion)\n",
    "                #label2.update()\n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)#to display emotion\n",
    "                shape = predictor(frame,detection)\n",
    "                shape = face_utils.shape_to_np(shape)#used to convert to numpy array which is used to easily detect the facial landmarks\n",
    "               \n",
    "                leyebrow = shape[lBegin:lEnd]\n",
    "                reyebrow = shape[rBegin:rEnd]\n",
    "                openmouth = shape[l_lower:l_upper]\n",
    "            # figuring out convex shape \n",
    "                reyebrowhull = cv2.convexHull(reyebrow) #eyebrow points are consdered as boundary and points inside form a cluster\n",
    "                leyebrowhull = cv2.convexHull(leyebrow) #A convex hull encloses a set of points and it acts as a cluster boundary which helps in determining all the points within a cluster.\n",
    "                openmouthhull = cv2.convexHull(openmouth) \n",
    "    \n",
    "                cv2.drawContours(frame, [reyebrowhull], -1, (0, 255, 0), 1) #the boundary color drawn around the eyebrow\n",
    "                cv2.drawContours(frame, [leyebrowhull], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(frame, [openmouthhull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Measuring lip distance and eye distance\n",
    "                \n",
    "                eyedist = ebdist(leyebrow[-1],reyebrow[0])\n",
    "                lipdist = lpdist(openmouth[-1],openmouth[0])\n",
    "                # calculate heart rate\n",
    "                fps=30\n",
    "                heart_rate = calculate_heart_rate(frame, fps) \n",
    "                \n",
    "                stress_value,stress_label = calculate_stress(points,eyedist, points_lip, lipdist,heart_rate)\n",
    "                stress_labels.append(stress_label)\n",
    "            #displaying stress levels and value \n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (235, 52, 52), 2)\n",
    "                cv2.putText(frame,\"stress value:{}\".format(str(int(stress_value*100))),(10,40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (51, 66, 232), 2)\n",
    "                cv2.putText(frame,\"Stress level:{}\".format((stress_label)),(10,60),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (35, 189, 25), 2)\n",
    "                cv2.putText(frame,\"Heart Rate: {} bpm\".format(int(heart_rate)), (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
    "                total_stress_value += stress_value\n",
    "                num_frames += 1\n",
    "\n",
    "            \n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "                \n",
    "            \n",
    "    def plt_show():\n",
    "        plot_stress=plt.plot(range(len(points)),points,'ro')\n",
    "        plt.title(\"Stress Levels\")\n",
    "        plt.show()\n",
    "        return plot_stress\n",
    "    \n",
    "    if num_frames > 0:\n",
    "        avg_stress_value = total_stress_value / num_frames\n",
    "        print('Average stress value:', avg_stress_value)\n",
    "        #return avg_stress_value\n",
    "    \n",
    "    mode_emotion = statistics.mode(emotions)\n",
    "    # create label widget to display mode of emotions\n",
    "    #label = Label(win,bg=\"#f5e4ef\", text=\"You're \",borderwidth=5,font=('Aerial 20 bold italic'))\n",
    "    #label.pack()\n",
    "\n",
    "    # update label with mode of emotions\n",
    "    label.config(text=\"You're : \" + mode_emotion)\n",
    "    #mode_stress_label = stats.mode(stress_labels)\n",
    "    #mode_label = Label(win, text=\"Mode of stress labels: \" + mode_stress_label)\n",
    "    #mode_label.pack()\n",
    "    # calculate and print average stress value\n",
    "    \n",
    "    if mode_emotion== 'Stressed':\n",
    "        mode_stress_label = statistics.mode(stress_labels)\n",
    "        label2.config(text=\"Stress level: \" + mode_stress_label)\n",
    "    else:\n",
    "        label2.config(text=\"You're perfect example for not stressing over things you can't control.\")\n",
    "        \n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    plt.plot(range(len(points)),points,'ro')\n",
    "    plt.title(\"Stress Levels\")\n",
    "    plt.show()\n",
    "#Label(win,text=\"Stress Detection!\",font=('Aerial 17 bold italic')).pack(pady=20)\n",
    "\n",
    "\n",
    "win.configure(bg='#f5e4ef')\n",
    "\n",
    "    \n",
    "tk.Button(win,bg=\"pink\",font=\"arial 24\",text=\"Stress Detection\",borderwidth=10,command=show_img).pack(pady=20)\n",
    "\n",
    "'''stress_label_var = tk.StringVar()\n",
    "stress_label_var.set(\"Stress level: \")\n",
    "stress_label = Label(win, textvariable=stress_label_var, font=('Arial 18 bold'), fg='#0a097a', bg='#f5e4ef')\n",
    "stress_label.pack(pady=20)'''\n",
    "\n",
    "def open_link(url):\n",
    "    webbrowser.open_new_tab(url)\n",
    "    \n",
    "#tk.Button(win,bg=\"pink\",text=\"Moderate?\",borderwidth=5,command=lambda: open_link(\"moderate.html\")).pack(side=\"top\",pady=0)\n",
    "#tk.Button(win,bg=\"pink\",text=\"High?\",borderwidth=5,command=lambda: open_link(\"https://www.google.com\")).pack(side=\"top\",pady=0)\n",
    "'''label = tk.Label(win, text=\"Average stress value: \")\n",
    "\n",
    "# Update the label text when needed\n",
    "def update_label():\n",
    "    label.config(text=\"Average stress value: {}\".format(average_stress_value))\n",
    "\n",
    "# Call the update_label function to update the label text\n",
    "update_label()\n",
    "\n",
    "# Add the label widget to the Tkinter window\n",
    "label.pack()'''\n",
    "\n",
    "tk.Label(win,bg='#f5e4ef', text=\"\", height=1).pack()\n",
    "Label(win,bg='#f5e4ef',text=\"Tips to tame stress:\",font=('Aerial 20 bold italic')).pack(pady=10)\n",
    "\n",
    "def create_label(text):\n",
    "    label = tk.Label(win,bg='#f5e4ef', text=text, wraplength=1100, justify=\"center\",font=('Helvetica 12 bold',15))\n",
    "    label.pack(pady=10)\n",
    "\n",
    "#canvas= Canvas(win, width= 1500, height= 750)\n",
    "create_label(\"Breaaatheeee!: Take slow, deep breaths to lower heart rate and blood pressure.\")\n",
    "create_label(\"Take a quick walk: When you’re feeling overwhelmed go for a quick stroll. You’ll get the benefits of alone time, physical activity, and a few minutes to gather your thoughts.\")\n",
    "create_label(\"Count Backward!: When worries are running rampant, try slowly counting to 10 and then back again to calm down.\")\n",
    "create_label(\"Stretch: Stand up for a quick stretch to relieve muscle tension which helps you relax.\")\n",
    "#create_label(\"Write it down buddy: Putting our emotions on paper can make them seem less intimidating, hence try journaling to calm your nerves.\")\n",
    "#create_label(\"Talk to a Friend: When something’s really bothering you, it can help to share your feelings with a buddy. Vent it out!!\")\n",
    "\n",
    "\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea21aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-5-54de4e9eb4f8>\", line 51, in show_img\n",
      "    from tensorflow.keras.utils import img_to_array\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 45, in <module>\n",
      "    from tensorflow.python.feature_column import feature_column_lib as feature_column\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py\", line 18, in <module>\n",
      "    from tensorflow.python.feature_column.feature_column import *\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 143, in <module>\n",
      "    from tensorflow.python.layers import base\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 16, in <module>\n",
      "    from tensorflow.python.keras.legacy_tf_layers import base\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\", line 25, in <module>\n",
      "    from tensorflow.python.keras import models\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\", line 22, in <module>\n",
      "    from tensorflow.python.keras.engine import functional\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 32, in <module>\n",
      "    from tensorflow.python.keras.engine import training as training_lib\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 54, in <module>\n",
      "    from tensorflow.python.keras.saving import hdf5_format\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\", line 37, in <module>\n",
      "    import h5py\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\h5py\\__init__.py\", line 46, in <module>\n",
      "    from ._conv import register_converters as _register_converters\n",
      "  File \"h5py\\h5t.pxd\", line 14, in init h5py._conv\n",
      "  File \"h5py\\h5t.pyx\", line 293, in init h5py.h5t\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\numpy\\__init__.py\", line 320, in __getattr__\n",
      "    raise AttributeError(\"module {!r} has no attribute \"\n",
      "AttributeError: module 'numpy' has no attribute 'typeDict'\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "import webbrowser\n",
    "import statistics\n",
    "import html\n",
    "\n",
    "from datetime import datetime\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "wb=Workbook()\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "from PIL import Image\n",
    "\n",
    "win=Tk()\n",
    "win.geometry(\"700x500\")\n",
    "Label(win,bg='#f5e4ef',text=\"Stress Detection through Facial Expressions\",font=('Aerial 24 bold italic')).pack(pady=20)\n",
    "bg=Image.open(\"download.jpg\")\n",
    "photo=ImageTk.PhotoImage(bg,master=win)\n",
    "\n",
    "\n",
    "label1=Label(win,image=photo)\n",
    "label1.place(x=0,y=0,relwidth=1,relheight=1)\n",
    "label1.image=bg\n",
    "label1.pack()\n",
    "\n",
    "label = Label(win,bg=\"#f5e4ef\",borderwidth=3,font=('Aerial 20 bold italic'))\n",
    "label.pack()\n",
    "\n",
    "label2 = Label(win,bg=\"#f5e4ef\",borderwidth=3,font=('Aerial 20 bold italic'))\n",
    "label2.pack()\n",
    "\n",
    "stress_labels = []\n",
    "\n",
    "#average_stress_value=0\n",
    "def show_img():\n",
    "    from scipy.spatial import distance as dist\n",
    "    from imutils.video import VideoStream\n",
    "    from imutils import face_utils\n",
    "    import numpy as np\n",
    "    import imutils\n",
    "    import time\n",
    "    import dlib\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "#from keras_preprocessing.image import img_to_array\n",
    "    from tensorflow.keras.utils import img_to_array\n",
    "    from keras.models import load_model\n",
    "\n",
    "# function to calculate heart rate\n",
    "    def calculate_heart_rate(color_signal, fps):\n",
    "        b, g, r = cv2.split(color_signal)\n",
    "        roi = g[150:350, 150:350]\n",
    "        mean_intensity = np.mean(roi)\n",
    "        heart_rate = mean_intensity * (60 * fps / 512)\n",
    "        return heart_rate/5\n",
    "\n",
    "    def ebdist(leye,reye):\n",
    "        eyedist = dist.euclidean(leye,reye)\n",
    "        points.append(int(eyedist))\n",
    "        return eyedist\n",
    "\n",
    "#calculating lip dostance using facial landmark\n",
    "    def lpdist(l_lower,l_upper):\n",
    "        lipdist = dist.euclidean(l_lower, l_upper)\n",
    "        points_lip.append(int(lipdist))\n",
    "        return lipdist\n",
    "    emotions = []\n",
    "#finding stressed or not using the emotions \n",
    "    def emotion_finder(faces,frame):\n",
    "        EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n",
    "        x,y,w,h = face_utils.rect_to_bb(faces)\n",
    "        frame = frame[y:y+h,x:x+w]\n",
    "        roi = cv2.resize(frame,(64,64))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi,axis=0)\n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "        if label in ['scared','sad','angry']:\n",
    "            label = 'Stressed'\n",
    "        else:\n",
    "            label = 'Not Stressed'\n",
    "        \n",
    "        return label\n",
    "    stress_values = []\n",
    "    \n",
    "# function to calculate stress level based on heart rate and facial features\n",
    "    def calculate_stress(points, eyedist, points_lip, lipdist, heart_rate):\n",
    "    # normalize values\n",
    "        norm_eyedist = eyedist / np.max(points)\n",
    "        norm_lipdist = lipdist / np.max(points_lip)\n",
    "        norm_hr = (heart_rate - 50) / 150\n",
    "    # calculate stress value\n",
    "        stress_value = 0.6 * norm_eyedist + 0.3 * norm_lipdist + 0.1 * norm_hr\n",
    "        \n",
    "        stress_values.append(stress_value)\n",
    "        \n",
    "    # calculate stress level based on stress value\n",
    "        if stress_value <= 0.66:\n",
    "            stress_label = \"Low\"\n",
    "        elif stress_value <= 0.80:\n",
    "            stress_label = \"Moderate\"\n",
    "        else:\n",
    "            stress_label = \"High\"\n",
    "        return stress_value, stress_label\n",
    "    global points, points_lip, emotion_classifier, detector, predictor,average_stress_value\n",
    "\n",
    "    emotion_classifier = load_model(\"_mini_XCEPTION.102-0.66.hdf5\", compile=False)\n",
    "    points = []; points_lip=[]\n",
    "\n",
    "# initialize video stream\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "# load face detector and facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# initialize heart rate calculation variables\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    color_signal = None\n",
    "    \n",
    "    total_stress_value = 0\n",
    "    num_frames = 0\n",
    "    stress_label = \"\"\n",
    "    while(True):    \n",
    "            ret,frame = cap.read()\n",
    "            frame = cv2.flip(frame,1)#to rotate img along x-axis and y-axis or both\n",
    "            frame = imutils.resize(frame, width=500,height=500)#imutils - for resizing,translation,rotation and displaying matplotlib imgs\n",
    "        #gettting points of eye from the facial landmark\n",
    "            (lBegin, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"]\n",
    "            (rBegin, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"]\n",
    "        # getting lip points from facial landmarks\n",
    "            (l_lower, l_upper) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "        #preprocessing the image\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "            detections = detector(gray,0)\n",
    "            for detection in detections:\n",
    "                emotion= emotion_finder(detection,gray)\n",
    "                emotions.append(emotion)\n",
    "                #label2.config(text=emotion)\n",
    "                #label2.update()\n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)#to display emotion\n",
    "                shape = predictor(frame,detection)\n",
    "                shape = face_utils.shape_to_np(shape)#used to convert to numpy array which is used to easily detect the facial landmarks\n",
    "               \n",
    "                leyebrow = shape[lBegin:lEnd]\n",
    "                reyebrow = shape[rBegin:rEnd]\n",
    "                openmouth = shape[l_lower:l_upper]\n",
    "            # figuring out convex shape \n",
    "                reyebrowhull = cv2.convexHull(reyebrow) #eyebrow points are consdered as boundary and points inside form a cluster\n",
    "                leyebrowhull = cv2.convexHull(leyebrow) #A convex hull encloses a set of points and it acts as a cluster boundary which helps in determining all the points within a cluster.\n",
    "                openmouthhull = cv2.convexHull(openmouth) \n",
    "    \n",
    "                cv2.drawContours(frame, [reyebrowhull], -1, (0, 255, 0), 1) #the boundary color drawn around the eyebrow\n",
    "                cv2.drawContours(frame, [leyebrowhull], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(frame, [openmouthhull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Measuring lip distance and eye distance\n",
    "                \n",
    "                eyedist = ebdist(leyebrow[-1],reyebrow[0])\n",
    "                lipdist = lpdist(openmouth[-1],openmouth[0])\n",
    "                # calculate heart rate\n",
    "                fps=30\n",
    "                heart_rate = calculate_heart_rate(frame, fps) \n",
    "                \n",
    "                stress_value,stress_label = calculate_stress(points,eyedist, points_lip, lipdist,heart_rate)\n",
    "                stress_labels.append(stress_label)\n",
    "            #displaying stress levels and value \n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (235, 52, 52), 2)\n",
    "                cv2.putText(frame,\"stress value:{}\".format(str(int(stress_value*100))),(10,40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (51, 66, 232), 2)\n",
    "                cv2.putText(frame,\"Stress level:{}\".format((stress_label)),(10,60),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (35, 189, 25), 2)\n",
    "                cv2.putText(frame,\"Heart Rate: {} bpm\".format(int(heart_rate)), (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
    "                total_stress_value += stress_value\n",
    "                num_frames += 1\n",
    "\n",
    "            \n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "                \n",
    "            \n",
    "    def plt_show():\n",
    "        plot_stress=plt.plot(range(len(points)),points,'ro')\n",
    "        plt.title(\"Stress Levels\")\n",
    "        plt.show()\n",
    "        return plot_stress\n",
    "    \n",
    "    if num_frames > 0:\n",
    "        avg_stress_value = total_stress_value / num_frames\n",
    "        print('Average stress value:', avg_stress_value)\n",
    "        #return avg_stress_value\n",
    "    \n",
    "    mode_emotion = statistics.mode(emotions)\n",
    "    # create label widget to display mode of emotions\n",
    "    #label = Label(win,bg=\"#f5e4ef\", text=\"You're \",borderwidth=5,font=('Aerial 20 bold italic'))\n",
    "    #label.pack()\n",
    "\n",
    "    # update label with mode of emotions\n",
    "    label.config(text=\"You're : \" + mode_emotion)\n",
    "    #mode_stress_label = stats.mode(stress_labels)\n",
    "    #mode_label = Label(win, text=\"Mode of stress labels: \" + mode_stress_label)\n",
    "    #mode_label.pack()\n",
    "    # calculate and print average stress value\n",
    "    \n",
    "    if mode_emotion== 'Stressed':\n",
    "        mode_stress_label = statistics.mode(stress_labels)\n",
    "        label2.config(text=\"Stress level: \" + mode_stress_label)\n",
    "        label3.config(text=\"Breaaatheeee!: Take slow, deep breaths to lower heart rate and blood pressure.\")\n",
    "    else:\n",
    "        label2.config(text=\"You're perfect example for not stressing over things you can't control.\")\n",
    "        \n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    plt.plot(range(len(points)),points,'ro')\n",
    "    plt.title(\"Stress Levels\")\n",
    "    plt.show()\n",
    "#Label(win,text=\"Stress Detection!\",font=('Aerial 17 bold italic')).pack(pady=20)\n",
    "\n",
    "\n",
    "win.configure(bg='#f5e4ef')\n",
    "\n",
    "    \n",
    "tk.Button(win,bg=\"pink\",font=\"arial 24\",text=\"Stress Detection\",borderwidth=10,command=show_img).pack(pady=20)\n",
    "\n",
    "'''stress_label_var = tk.StringVar()\n",
    "stress_label_var.set(\"Stress level: \")\n",
    "stress_label = Label(win, textvariable=stress_label_var, font=('Arial 18 bold'), fg='#0a097a', bg='#f5e4ef')\n",
    "stress_label.pack(pady=20)'''\n",
    "\n",
    "def open_link(url):\n",
    "    webbrowser.open_new_tab(url)\n",
    "    \n",
    "#tk.Button(win,bg=\"pink\",text=\"Moderate?\",borderwidth=5,command=lambda: open_link(\"moderate.html\")).pack(side=\"top\",pady=0)\n",
    "#tk.Button(win,bg=\"pink\",text=\"High?\",borderwidth=5,command=lambda: open_link(\"https://www.google.com\")).pack(side=\"top\",pady=0)\n",
    "'''label = tk.Label(win, text=\"Average stress value: \")\n",
    "\n",
    "# Update the label text when needed\n",
    "def update_label():\n",
    "    label.config(text=\"Average stress value: {}\".format(average_stress_value))\n",
    "\n",
    "# Call the update_label function to update the label text\n",
    "update_label()\n",
    "\n",
    "# Add the label widget to the Tkinter window\n",
    "label.pack()'''\n",
    "\n",
    "tk.Label(win,bg='#f5e4ef', text=\"\", height=1).pack()\n",
    "Label(win,bg='#f5e4ef',text=\"Tips to tame stress:\",font=('Aerial 20 bold italic')).pack(pady=10)\n",
    "\n",
    "def create_label(text):\n",
    "    label = tk.Label(win,bg='#f5e4ef', text=text, wraplength=1100, justify=\"center\",font=('Helvetica 12 bold',15))\n",
    "    label.pack(pady=10)\n",
    "\n",
    "#canvas= Canvas(win, width= 1500, height= 750)\n",
    "create_label(\"Breaaatheeee!: Take slow, deep breaths to lower heart rate and blood pressure.\")\n",
    "create_label(\"Take a quick walk: When you’re feeling overwhelmed go for a quick stroll. You’ll get the benefits of alone time, physical activity, and a few minutes to gather your thoughts.\")\n",
    "create_label(\"Count Backward!: When worries are running rampant, try slowly counting to 10 and then back again to calm down.\")\n",
    "create_label(\"Stretch: Stand up for a quick stretch to relieve muscle tension which helps you relax.\")\n",
    "#create_label(\"Write it down buddy: Putting our emotions on paper can make them seem less intimidating, hence try journaling to calm your nerves.\")\n",
    "#create_label(\"Talk to a Friend: When something’s really bothering you, it can help to share your feelings with a buddy. Vent it out!!\")\n",
    "\n",
    "\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c19ebb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "# create a tkinter window\n",
    "win = tk.Tk()\n",
    "\n",
    "# create a canvas\n",
    "canvas = tk.Canvas(win)\n",
    "canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "# create a scrollbar\n",
    "scrollbar = tk.Scrollbar(win, orient=tk.VERTICAL, command=canvas.yview)\n",
    "scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "# configure the canvas to use the scrollbar\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "# create a frame inside the canvas to hold the widgets\n",
    "frame = tk.Frame(canvas)\n",
    "canvas.create_window((0, 0), window=frame, anchor=\"nw\")\n",
    "\n",
    "# add widgets to the frame\n",
    "for i in range(20):\n",
    "    tk.Label(frame, text=f\"Label {i}\").pack()\n",
    "\n",
    "# configure the canvas to resize when the frame is resized\n",
    "frame.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "\n",
    "# run the tkinter event loop\n",
    "win.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470ae4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-1-59783dcdd517>\", line 40, in show_img\n",
      "    from tensorflow.keras.utils import img_to_array\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 45, in <module>\n",
      "    from tensorflow.python.feature_column import feature_column_lib as feature_column\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py\", line 18, in <module>\n",
      "    from tensorflow.python.feature_column.feature_column import *\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 143, in <module>\n",
      "    from tensorflow.python.layers import base\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 16, in <module>\n",
      "    from tensorflow.python.keras.legacy_tf_layers import base\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\", line 25, in <module>\n",
      "    from tensorflow.python.keras import models\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\", line 22, in <module>\n",
      "    from tensorflow.python.keras.engine import functional\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 32, in <module>\n",
      "    from tensorflow.python.keras.engine import training as training_lib\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 54, in <module>\n",
      "    from tensorflow.python.keras.saving import hdf5_format\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\", line 37, in <module>\n",
      "    import h5py\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\h5py\\__init__.py\", line 46, in <module>\n",
      "    from ._conv import register_converters as _register_converters\n",
      "  File \"h5py\\h5t.pxd\", line 14, in init h5py._conv\n",
      "  File \"h5py\\h5t.pyx\", line 293, in init h5py.h5t\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\numpy\\__init__.py\", line 320, in __getattr__\n",
      "    raise AttributeError(\"module {!r} has no attribute \"\n",
      "AttributeError: module 'numpy' has no attribute 'typeDict'\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "import webbrowser\n",
    "\n",
    "from datetime import datetime\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "wb=Workbook()\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "from PIL import Image\n",
    "\n",
    "win=Tk()\n",
    "win.geometry(\"700x500\")\n",
    "Label(win,bg='#f5e4ef',text=\"Stress Detection through Facial Expressions\",font=('Aerial 24 bold italic')).pack(pady=20)\n",
    "bg=Image.open(\"download.jpg\")\n",
    "photo=ImageTk.PhotoImage(bg,master=win)\n",
    "\n",
    "label1=Label(win,image=photo)\n",
    "label1.place(x=0,y=0,relwidth=1,relheight=1)\n",
    "label1.image=bg\n",
    "label1.pack()\n",
    "\n",
    "#average_stress_value=0\n",
    "def show_img():\n",
    "    from scipy.spatial import distance as dist\n",
    "    from imutils.video import VideoStream\n",
    "    from imutils import face_utils\n",
    "    import numpy as np\n",
    "    import imutils\n",
    "    import time\n",
    "    import dlib\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "#from keras_preprocessing.image import img_to_array\n",
    "    from tensorflow.keras.utils import img_to_array\n",
    "    from keras.models import load_model\n",
    "\n",
    "# function to calculate heart rate\n",
    "    def calculate_heart_rate(color_signal, fps):\n",
    "        b, g, r = cv2.split(color_signal)\n",
    "        roi = g[150:350, 150:350]\n",
    "        mean_intensity = np.mean(roi)\n",
    "        heart_rate = mean_intensity * (60 * fps / 512)\n",
    "        return heart_rate/5\n",
    "\n",
    "    def ebdist(leye,reye):\n",
    "        eyedist = dist.euclidean(leye,reye)\n",
    "        points.append(int(eyedist))\n",
    "        return eyedist\n",
    "\n",
    "#calculating lip dostance using facial landmark\n",
    "    def lpdist(l_lower,l_upper):\n",
    "        lipdist = dist.euclidean(l_lower, l_upper)\n",
    "        points_lip.append(int(lipdist))\n",
    "        return lipdist\n",
    "\n",
    "#finding stressed or not using the emotions \n",
    "    def emotion_finder(faces,frame):\n",
    "        EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n",
    "        x,y,w,h = face_utils.rect_to_bb(faces)\n",
    "        frame = frame[y:y+h,x:x+w]\n",
    "        roi = cv2.resize(frame,(64,64))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi,axis=0)\n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "        if label in ['scared','sad','angry']:\n",
    "            label = 'Stressed'\n",
    "        else:\n",
    "            label = 'Not Stressed'\n",
    "        return label\n",
    "    stress_values = []\n",
    "# function to calculate stress level based on heart rate and facial features\n",
    "    def calculate_stress(points, eyedist, points_lip, lipdist, heart_rate):\n",
    "    # normalize values\n",
    "        norm_eyedist = eyedist / np.max(points)\n",
    "        norm_lipdist = lipdist / np.max(points_lip)\n",
    "        norm_hr = (heart_rate - 50) / 150\n",
    "    # calculate stress value\n",
    "        stress_value = 0.6 * norm_eyedist + 0.3 * norm_lipdist + 0.1 * norm_hr\n",
    "        \n",
    "        stress_values.append(stress_value)\n",
    "    # calculate stress level based on stress value\n",
    "        if stress_value <= 0.60:\n",
    "            stress_label = \"Low\"\n",
    "        elif stress_value <= 0.90:\n",
    "            stress_label = \"Moderate\"\n",
    "        else:\n",
    "            stress_label = \"High\"\n",
    "        return stress_value, stress_label\n",
    "    global points, points_lip, emotion_classifier, detector, predictor,average_stress_value\n",
    "\n",
    "    emotion_classifier = load_model(\"_mini_XCEPTION.102-0.66.hdf5\", compile=False)\n",
    "    points = []; points_lip=[]\n",
    "\n",
    "# initialize video stream\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "# load face detector and facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# initialize heart rate calculation variables\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    color_signal = None\n",
    "    \n",
    "    total_stress_value = 0\n",
    "    num_frames = 0\n",
    "    stress_label = \"\"\n",
    "    while(True):    \n",
    "            ret,frame = cap.read()\n",
    "            frame = cv2.flip(frame,1)#to rotate img along x-axis and y-axis or both\n",
    "            frame = imutils.resize(frame, width=500,height=500)#imutils - for resizing,translation,rotation and displaying matplotlib imgs\n",
    "        #gettting points of eye from the facial landmark\n",
    "            (lBegin, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"]\n",
    "            (rBegin, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"]\n",
    "        # getting lip points from facial landmarks\n",
    "            (l_lower, l_upper) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "        #preprocessing the image\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "            detections = detector(gray,0)\n",
    "            for detection in detections:\n",
    "                emotion= emotion_finder(detection,gray)\n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                #to display emotion\n",
    "                shape = predictor(frame,detection)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "                #used to convert to numpy array which is used to easily detect the facial landmarks\n",
    "               \n",
    "                leyebrow = shape[lBegin:lEnd]\n",
    "                reyebrow = shape[rBegin:rEnd]\n",
    "                openmouth = shape[l_lower:l_upper]\n",
    "            # figuring out convex shape \n",
    "                reyebrowhull = cv2.convexHull(reyebrow) #eyebrow points are consdered as boundary and points\n",
    "                #inside form a cluster\n",
    "                leyebrowhull = cv2.convexHull(leyebrow) #A convex hull encloses a set of points and\n",
    "                #it acts as a cluster boundary which helps in determining all the points within a cluster.\n",
    "                openmouthhull = cv2.convexHull(openmouth) \n",
    "    \n",
    "                cv2.drawContours(frame, [reyebrowhull], -1, (0, 255, 0), 1) #the boundary color drawn \n",
    "                #around the eyebrow\n",
    "                cv2.drawContours(frame, [leyebrowhull], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(frame, [openmouthhull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Measuring lip distance and eye distance\n",
    "                \n",
    "                eyedist = ebdist(leyebrow[-1],reyebrow[0])\n",
    "                lipdist = lpdist(openmouth[-1],openmouth[0])\n",
    "                # calculate heart rate\n",
    "                fps=30\n",
    "                heart_rate = calculate_heart_rate(frame, fps) \n",
    "                \n",
    "                stress_value,stress_label = calculate_stress(points,eyedist, points_lip, lipdist,heart_rate)\n",
    "                stress_label_var.set(\"Stress level: \" + stress_label)\n",
    "            #displaying stress levels and value \n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (235, 52, 52), 2)\n",
    "                cv2.putText(frame,\"stress value:{}\".format(str(int(stress_value*100))),(10,40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (51, 66, 232), 2)\n",
    "                cv2.putText(frame,\"Stress level:{}\".format((stress_label)),(10,60),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (35, 189, 25), 2)\n",
    "                cv2.putText(frame,\"Heart Rate: {} bpm\".format(int(heart_rate)), (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
    "                total_stress_value += stress_value\n",
    "                num_frames += 1\n",
    "\n",
    "            \n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "                \n",
    "            \n",
    "    def plt_show():\n",
    "        plot_stress=plt.plot(range(len(points)),points,'ro')\n",
    "        plt.title(\"Stress Levels\")\n",
    "        plt.show()\n",
    "        return plot_stress\n",
    "    \n",
    "    # calculate and print average stress value\n",
    "    if num_frames > 0:\n",
    "        avg_stress_value = total_stress_value / num_frames\n",
    "        print('Average stress value:', avg_stress_value)\n",
    "        #return avg_stress_value\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    plt.plot(range(len(points)),points,'ro')\n",
    "    plt.title(\"Stress Levels\")\n",
    "    plt.show()\n",
    "#Label(win,text=\"Stress Detection!\",font=('Aerial 17 bold italic')).pack(pady=20)\n",
    "    \n",
    "win.configure(bg='#f5e4ef')\n",
    "tk.Button(win,bg=\"pink\",font=\"arial 24\",text=\"Stress Detection\",borderwidth=10,command=show_img).pack(pady=20)\n",
    "\n",
    "stress_label_var = tk.StringVar()\n",
    "stress_label_var.set(\"Stress level: \")\n",
    "stress_label = Label(win, textvariable=stress_label_var, font=('Arial 18 bold'), fg='#0a097a', bg='#f5e4ef')\n",
    "stress_label.pack(pady=20)\n",
    "\n",
    "'''label = tk.Label(win, text=\"Average stress value: \")\n",
    "\n",
    "# Update the label text when needed\n",
    "def update_label():\n",
    "    label.config(text=\"Average stress value: {}\".format(average_stress_value))\n",
    "\n",
    "# Call the update_label function to update the label text\n",
    "update_label()\n",
    "\n",
    "# Add the label widget to the Tkinter window\n",
    "label.pack()'''\n",
    "\n",
    "\n",
    "Label(win,bg='#f5e4ef',text=\"Tips to tame stress:\",font=('Aerial 20 bold italic')).pack(pady=10)\n",
    "\n",
    "def create_label(text):\n",
    "    label = tk.Label(win,bg='#f5e4ef', text=text, wraplength=1100, justify=\"center\",font=('Helvetica 12 bold',15))\n",
    "    label.pack(pady=10)\n",
    "\n",
    "#canvas= Canvas(win, width= 1500, height= 750)\n",
    "create_label(\"Breaaatheeee!: Take slow, deep breaths to lower heart rate and blood pressure.\")\n",
    "create_label(\"Take a quick walk: When you’re feeling overwhelmed go for a quick stroll. You’ll get the benefits of alone time, physical activity, and a few minutes to gather your thoughts.\")\n",
    "create_label(\"Count Backward!: When worries are running rampant, try slowly counting to 10 and then back again to calm down.\")\n",
    "create_label(\"Stretch: Stand up for a quick stretch to relieve muscle tension which helps you relax.\")\n",
    "#create_label(\"Write it down buddy: Putting our emotions on paper can make them seem less intimidating, hence try journaling to calm your nerves.\")\n",
    "#create_label(\"Talk to a Friend: When something’s really bothering you, it can help to share your feelings with a buddy. Vent it out!!\")\n",
    "\n",
    "\n",
    "\n",
    "#canvas.pack()\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1975372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-8-59783dcdd517>\", line 40, in show_img\n",
      "    from tensorflow.keras.utils import img_to_array\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 45, in <module>\n",
      "    from tensorflow.python.feature_column import feature_column_lib as feature_column\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py\", line 18, in <module>\n",
      "    from tensorflow.python.feature_column.feature_column import *\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 143, in <module>\n",
      "    from tensorflow.python.layers import base\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 16, in <module>\n",
      "    from tensorflow.python.keras.legacy_tf_layers import base\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\", line 25, in <module>\n",
      "    from tensorflow.python.keras import models\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\", line 22, in <module>\n",
      "    from tensorflow.python.keras.engine import functional\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 32, in <module>\n",
      "    from tensorflow.python.keras.engine import training as training_lib\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 54, in <module>\n",
      "    from tensorflow.python.keras.saving import hdf5_format\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\", line 37, in <module>\n",
      "    import h5py\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\h5py\\__init__.py\", line 46, in <module>\n",
      "    from ._conv import register_converters as _register_converters\n",
      "  File \"h5py\\h5t.pxd\", line 14, in init h5py._conv\n",
      "  File \"h5py\\h5t.pyx\", line 293, in init h5py.h5t\n",
      "  File \"C:\\Users\\JOY PRINCY\\anaconda3\\lib\\site-packages\\numpy\\__init__.py\", line 320, in __getattr__\n",
      "    raise AttributeError(\"module {!r} has no attribute \"\n",
      "AttributeError: module 'numpy' has no attribute 'typeDict'\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "import webbrowser\n",
    "\n",
    "from datetime import datetime\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "wb=Workbook()\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "from PIL import Image\n",
    "\n",
    "win=Tk()\n",
    "win.geometry(\"700x500\")\n",
    "Label(win,bg='#f5e4ef',text=\"Stress Detection through Facial Expressions\",font=('Aerial 24 bold italic')).pack(pady=20)\n",
    "bg=Image.open(\"download.jpg\")\n",
    "photo=ImageTk.PhotoImage(bg,master=win)\n",
    "\n",
    "label1=Label(win,image=photo)\n",
    "label1.place(x=0,y=0,relwidth=1,relheight=1)\n",
    "label1.image=bg\n",
    "label1.pack()\n",
    "\n",
    "#average_stress_value=0\n",
    "def show_img():\n",
    "    from scipy.spatial import distance as dist\n",
    "    from imutils.video import VideoStream\n",
    "    from imutils import face_utils\n",
    "    import numpy as np\n",
    "    import imutils\n",
    "    import time\n",
    "    import dlib\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "#from keras_preprocessing.image import img_to_array\n",
    "    from tensorflow.keras.utils import img_to_array\n",
    "    from keras.models import load_model\n",
    "\n",
    "# function to calculate heart rate\n",
    "    def calculate_heart_rate(color_signal, fps):\n",
    "        b, g, r = cv2.split(color_signal)\n",
    "        roi = g[150:350, 150:350]\n",
    "        mean_intensity = np.mean(roi)\n",
    "        heart_rate = mean_intensity * (60 * fps / 512)\n",
    "        return heart_rate/5\n",
    "\n",
    "    def ebdist(leye,reye):\n",
    "        eyedist = dist.euclidean(leye,reye)\n",
    "        points.append(int(eyedist))\n",
    "        return eyedist\n",
    "\n",
    "#calculating lip dostance using facial landmark\n",
    "    def lpdist(l_lower,l_upper):\n",
    "        lipdist = dist.euclidean(l_lower, l_upper)\n",
    "        points_lip.append(int(lipdist))\n",
    "        return lipdist\n",
    "\n",
    "#finding stressed or not using the emotions \n",
    "    def emotion_finder(faces,frame):\n",
    "        EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n",
    "        x,y,w,h = face_utils.rect_to_bb(faces)\n",
    "        frame = frame[y:y+h,x:x+w]\n",
    "        roi = cv2.resize(frame,(64,64))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi,axis=0)\n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "        if label in ['scared','sad','angry']:\n",
    "            label = 'Stressed'\n",
    "        else:\n",
    "            label = 'Not Stressed'\n",
    "        return label\n",
    "    stress_values = []\n",
    "# function to calculate stress level based on heart rate and facial features\n",
    "    def calculate_stress(points, eyedist, points_lip, lipdist, heart_rate):\n",
    "    # normalize values\n",
    "        norm_eyedist = eyedist / np.max(points)\n",
    "        norm_lipdist = lipdist / np.max(points_lip)\n",
    "        norm_hr = (heart_rate - 50) / 150\n",
    "    # calculate stress value\n",
    "        stress_value = 0.6 * norm_eyedist + 0.3 * norm_lipdist + 0.1 * norm_hr\n",
    "        \n",
    "        stress_values.append(stress_value)\n",
    "    # calculate stress level based on stress value\n",
    "        if stress_value <= 0.60:\n",
    "            stress_label = \"Low\"\n",
    "        elif stress_value <= 0.90:\n",
    "            stress_label = \"Moderate\"\n",
    "        else:\n",
    "            stress_label = \"High\"\n",
    "        return stress_value, stress_label\n",
    "    global points, points_lip, emotion_classifier, detector, predictor,average_stress_value\n",
    "\n",
    "    emotion_classifier = load_model(\"_mini_XCEPTION.102-0.66.hdf5\", compile=False)\n",
    "    points = []; points_lip=[]\n",
    "\n",
    "# initialize video stream\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "# load face detector and facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# initialize heart rate calculation variables\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    color_signal = None\n",
    "    \n",
    "    total_stress_value = 0\n",
    "    num_frames = 0\n",
    "    stress_label = \"\"\n",
    "    while(True):    \n",
    "            ret,frame = cap.read()\n",
    "            frame = cv2.flip(frame,1)#to rotate img along x-axis and y-axis or both\n",
    "            frame = imutils.resize(frame, width=500,height=500)#imutils - for resizing,translation,rotation and displaying matplotlib imgs\n",
    "        #gettting points of eye from the facial landmark\n",
    "            (lBegin, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"]\n",
    "            (rBegin, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"]\n",
    "        # getting lip points from facial landmarks\n",
    "            (l_lower, l_upper) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "        #preprocessing the image\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "            detections = detector(gray,0)\n",
    "            for detection in detections:\n",
    "                emotion= emotion_finder(detection,gray)\n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                #to display emotion\n",
    "                shape = predictor(frame,detection)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "                #used to convert to numpy array which is used to easily detect the facial landmarks\n",
    "               \n",
    "                leyebrow = shape[lBegin:lEnd]\n",
    "                reyebrow = shape[rBegin:rEnd]\n",
    "                openmouth = shape[l_lower:l_upper]\n",
    "            # figuring out convex shape \n",
    "                reyebrowhull = cv2.convexHull(reyebrow) #eyebrow points are consdered as boundary and points\n",
    "                #inside form a cluster\n",
    "                leyebrowhull = cv2.convexHull(leyebrow) #A convex hull encloses a set of points and\n",
    "                #it acts as a cluster boundary which helps in determining all the points within a cluster.\n",
    "                openmouthhull = cv2.convexHull(openmouth) \n",
    "    \n",
    "                cv2.drawContours(frame, [reyebrowhull], -1, (0, 255, 0), 1) #the boundary color drawn \n",
    "                #around the eyebrow\n",
    "                cv2.drawContours(frame, [leyebrowhull], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(frame, [openmouthhull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Measuring lip distance and eye distance\n",
    "                \n",
    "                eyedist = ebdist(leyebrow[-1],reyebrow[0])\n",
    "                lipdist = lpdist(openmouth[-1],openmouth[0])\n",
    "                # calculate heart rate\n",
    "                fps=30\n",
    "                heart_rate = calculate_heart_rate(frame, fps) \n",
    "                \n",
    "                stress_value,stress_label = calculate_stress(points,eyedist, points_lip, lipdist,heart_rate)\n",
    "                stress_label_var.set(\"Stress level: \" + stress_label)\n",
    "            #displaying stress levels and value \n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (235, 52, 52), 2)\n",
    "                cv2.putText(frame,\"stress value:{}\".format(str(int(stress_value*100))),(10,40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (51, 66, 232), 2)\n",
    "                cv2.putText(frame,\"Stress level:{}\".format((stress_label)),(10,60),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (35, 189, 25), 2)\n",
    "                cv2.putText(frame,\"Heart Rate: {} bpm\".format(int(heart_rate)), (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
    "                total_stress_value += stress_value\n",
    "                num_frames += 1\n",
    "\n",
    "            \n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "                \n",
    "            \n",
    "    def plt_show():\n",
    "        plot_stress=plt.plot(range(len(points)),points,'ro')\n",
    "        plt.title(\"Stress Levels\")\n",
    "        plt.show()\n",
    "        return plot_stress\n",
    "    \n",
    "    # calculate and print average stress value\n",
    "    if num_frames > 0:\n",
    "        avg_stress_value = total_stress_value / num_frames\n",
    "        print('Average stress value:', avg_stress_value)\n",
    "        #return avg_stress_value\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    plt.plot(range(len(points)),points,'ro')\n",
    "    plt.title(\"Stress Levels\")\n",
    "    plt.show()\n",
    "#Label(win,text=\"Stress Detection!\",font=('Aerial 17 bold italic')).pack(pady=20)\n",
    "    \n",
    "win.configure(bg='#f5e4ef')\n",
    "tk.Button(win,bg=\"pink\",font=\"arial 24\",text=\"Stress Detection\",borderwidth=10,command=show_img).pack(pady=20)\n",
    "\n",
    "stress_label_var = tk.StringVar()\n",
    "stress_label_var.set(\"Stress level: \")\n",
    "stress_label = Label(win, textvariable=stress_label_var, font=('Arial 18 bold'), fg='#0a097a', bg='#f5e4ef')\n",
    "stress_label.pack(pady=20)\n",
    "\n",
    "'''label = tk.Label(win, text=\"Average stress value: \")\n",
    "\n",
    "# Update the label text when needed\n",
    "def update_label():\n",
    "    label.config(text=\"Average stress value: {}\".format(average_stress_value))\n",
    "\n",
    "# Call the update_label function to update the label text\n",
    "update_label()\n",
    "\n",
    "# Add the label widget to the Tkinter window\n",
    "label.pack()'''\n",
    "\n",
    "\n",
    "Label(win,bg='#f5e4ef',text=\"Tips to tame stress:\",font=('Aerial 20 bold italic')).pack(pady=10)\n",
    "\n",
    "def create_label(text):\n",
    "    label = tk.Label(win,bg='#f5e4ef', text=text, wraplength=1100, justify=\"center\",font=('Helvetica 12 bold',15))\n",
    "    label.pack(pady=10)\n",
    "\n",
    "#canvas= Canvas(win, width= 1500, height= 750)\n",
    "create_label(\"Breaaatheeee!: Take slow, deep breaths to lower heart rate and blood pressure.\")\n",
    "create_label(\"Take a quick walk: When you’re feeling overwhelmed go for a quick stroll. You’ll get the benefits of alone time, physical activity, and a few minutes to gather your thoughts.\")\n",
    "create_label(\"Count Backward!: When worries are running rampant, try slowly counting to 10 and then back again to calm down.\")\n",
    "create_label(\"Stretch: Stand up for a quick stretch to relieve muscle tension which helps you relax.\")\n",
    "#create_label(\"Write it down buddy: Putting our emotions on paper can make them seem less intimidating, hence try journaling to calm your nerves.\")\n",
    "#create_label(\"Talk to a Friend: When something’s really bothering you, it can help to share your feelings with a buddy. Vent it out!!\")\n",
    "\n",
    "\n",
    "\n",
    "#canvas.pack()\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "020539ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (20.9)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\joy princy\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (2.4.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\joy princy\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ebd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ce9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "import webbrowser\n",
    "\n",
    "from datetime import datetime\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "wb=Workbook()\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "from PIL import Image\n",
    "\n",
    "win=Tk()\n",
    "win.geometry(\"700x500\")\n",
    "Label(win,bg='#f5e4ef',text=\"Stress Detection through Facial Expressions\",font=('Aerial 24 bold italic')).pack(pady=20)\n",
    "bg=Image.open(\"download.jpg\")\n",
    "photo=ImageTk.PhotoImage(bg,master=win)\n",
    "\n",
    "label1=Label(win,image=photo)\n",
    "label1.place(x=0,y=0,relwidth=1,relheight=1)\n",
    "label1.image=bg\n",
    "label1.pack()\n",
    "\n",
    "#average_stress_value=0\n",
    "def show_img():\n",
    "    from scipy.spatial import distance as dist\n",
    "    from imutils.video import VideoStream\n",
    "    from imutils import face_utils\n",
    "    import numpy as np\n",
    "    import imutils\n",
    "    import time\n",
    "    import dlib\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "#from keras_preprocessing.image import img_to_array\n",
    "    from tensorflow.keras.utils import img_to_array\n",
    "    from keras.models import load_model\n",
    "\n",
    "# function to calculate heart rate\n",
    "    def calculate_heart_rate(color_signal, fps):\n",
    "        b, g, r = cv2.split(color_signal)\n",
    "        roi = g[150:350, 150:350]\n",
    "        mean_intensity = np.mean(roi)\n",
    "        heart_rate = mean_intensity * (60 * fps / 512)\n",
    "        return heart_rate/5\n",
    "\n",
    "    def ebdist(leye,reye):\n",
    "        eyedist = dist.euclidean(leye,reye)\n",
    "        points.append(int(eyedist))\n",
    "        return eyedist\n",
    "\n",
    "#calculating lip dostance using facial landmark\n",
    "    def lpdist(l_lower,l_upper):\n",
    "        lipdist = dist.euclidean(l_lower, l_upper)\n",
    "        points_lip.append(int(lipdist))\n",
    "        return lipdist\n",
    "\n",
    "#finding stressed or not using the emotions \n",
    "    def emotion_finder(faces,frame):\n",
    "        EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n",
    "        x,y,w,h = face_utils.rect_to_bb(faces)\n",
    "        frame = frame[y:y+h,x:x+w]\n",
    "        roi = cv2.resize(frame,(64,64))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi,axis=0)\n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "        if label in ['scared','sad','angry']:\n",
    "            label = 'Stressed'\n",
    "        else:\n",
    "            label = 'Not Stressed'\n",
    "        return label\n",
    "    stress_values = []\n",
    "# function to calculate stress level based on heart rate and facial features\n",
    "    def calculate_stress(points, eyedist, points_lip, lipdist, heart_rate):\n",
    "    # normalize values\n",
    "        norm_eyedist = eyedist / np.max(points)\n",
    "        norm_lipdist = lipdist / np.max(points_lip)\n",
    "        norm_hr = (heart_rate - 50) / 150\n",
    "    # calculate stress value\n",
    "        stress_value = 0.6 * norm_eyedist + 0.3 * norm_lipdist + 0.1 * norm_hr\n",
    "        \n",
    "        stress_values.append(stress_value)\n",
    "    # calculate stress level based on stress value\n",
    "        if stress_value <= 0.60:\n",
    "            stress_label = \"Low\"\n",
    "        elif stress_value <= 0.90:\n",
    "            stress_label = \"Moderate\"\n",
    "        else:\n",
    "            stress_label = \"High\"\n",
    "        return stress_value, stress_label\n",
    "    global points, points_lip, emotion_classifier, detector, predictor,average_stress_value\n",
    "\n",
    "    emotion_classifier = load_model(\"_mini_XCEPTION.102-0.66.hdf5\", compile=False)\n",
    "    points = []; points_lip=[]\n",
    "\n",
    "# initialize video stream\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "# load face detector and facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# initialize heart rate calculation variables\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    color_signal = None\n",
    "    \n",
    "    total_stress_value = 0\n",
    "    num_frames = 0\n",
    "    stress_label = \"\"\n",
    "    while(True):    \n",
    "            ret,frame = cap.read()\n",
    "            frame = cv2.flip(frame,1)#to rotate img along x-axis and y-axis or both\n",
    "            frame = imutils.resize(frame, width=500,height=500)#imutils - for resizing,translation,rotation and displaying matplotlib imgs\n",
    "        #gettting points of eye from the facial landmark\n",
    "            (lBegin, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"]\n",
    "            (rBegin, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"]\n",
    "        # getting lip points from facial landmarks\n",
    "            (l_lower, l_upper) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "        #preprocessing the image\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "            detections = detector(gray,0)\n",
    "            for detection in detections:\n",
    "                emotion= emotion_finder(detection,gray)\n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                #to display emotion\n",
    "                shape = predictor(frame,detection)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "                #used to convert to numpy array which is used to easily detect the facial landmarks\n",
    "               \n",
    "                leyebrow = shape[lBegin:lEnd]\n",
    "                reyebrow = shape[rBegin:rEnd]\n",
    "                openmouth = shape[l_lower:l_upper]\n",
    "            # figuring out convex shape \n",
    "                reyebrowhull = cv2.convexHull(reyebrow) #eyebrow points are consdered as boundary and points\n",
    "                #inside form a cluster\n",
    "                leyebrowhull = cv2.convexHull(leyebrow) #A convex hull encloses a set of points and\n",
    "                #it acts as a cluster boundary which helps in determining all the points within a cluster.\n",
    "                openmouthhull = cv2.convexHull(openmouth) \n",
    "    \n",
    "                cv2.drawContours(frame, [reyebrowhull], -1, (0, 255, 0), 1) #the boundary color drawn \n",
    "                #around the eyebrow\n",
    "                cv2.drawContours(frame, [leyebrowhull], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(frame, [openmouthhull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Measuring lip distance and eye distance\n",
    "                \n",
    "                eyedist = ebdist(leyebrow[-1],reyebrow[0])\n",
    "                lipdist = lpdist(openmouth[-1],openmouth[0])\n",
    "                # calculate heart rate\n",
    "                fps=30\n",
    "                heart_rate = calculate_heart_rate(frame, fps) \n",
    "                \n",
    "                stress_value,stress_label = calculate_stress(points,eyedist, points_lip, lipdist,heart_rate)\n",
    "                stress_label_var.set(\"Stress level: \" + stress_label)\n",
    "            #displaying stress levels and value \n",
    "                cv2.putText(frame, emotion, (10,10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (235, 52, 52), 2)\n",
    "                cv2.putText(frame,\"stress value:{}\".format(str(int(stress_value*100))),(10,40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (51, 66, 232), 2)\n",
    "                cv2.putText(frame,\"Stress level:{}\".format((stress_label)),(10,60),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (35, 189, 25), 2)\n",
    "                cv2.putText(frame,\"Heart Rate: {} bpm\".format(int(heart_rate)), (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
    "                total_stress_value += stress_value\n",
    "                num_frames += 1\n",
    "\n",
    "            \n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "                \n",
    "            \n",
    "    def plt_show():\n",
    "        plot_stress=plt.plot(range(len(points)),points,'ro')\n",
    "        plt.title(\"Stress Levels\")\n",
    "        plt.show()\n",
    "        return plot_stress\n",
    "    \n",
    "    # calculate and print average stress value\n",
    "    if num_frames > 0:\n",
    "        avg_stress_value = total_stress_value / num_frames\n",
    "        print('Average stress value:', avg_stress_value)\n",
    "        #return avg_stress_value\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    plt.plot(range(len(points)),points,'ro')\n",
    "    plt.title(\"Stress Levels\")\n",
    "    plt.show()\n",
    "#Label(win,text=\"Stress Detection!\",font=('Aerial 17 bold italic')).pack(pady=20)\n",
    "    \n",
    "win.configure(bg='#f5e4ef')\n",
    "tk.Button(win,bg=\"pink\",font=\"arial 24\",text=\"Stress Detection\",borderwidth=10,command=show_img).pack(pady=20)\n",
    "\n",
    "stress_label_var = tk.StringVar()\n",
    "stress_label_var.set(\"Stress level: \")\n",
    "stress_label = Label(win, textvariable=stress_label_var, font=('Arial 18 bold'), fg='#0a097a', bg='#f5e4ef')\n",
    "stress_label.pack(pady=20)\n",
    "\n",
    "'''label = tk.Label(win, text=\"Average stress value: \")\n",
    "\n",
    "# Update the label text when needed\n",
    "def update_label():\n",
    "    label.config(text=\"Average stress value: {}\".format(average_stress_value))\n",
    "\n",
    "# Call the update_label function to update the label text\n",
    "update_label()\n",
    "\n",
    "# Add the label widget to the Tkinter window\n",
    "label.pack()'''\n",
    "\n",
    "\n",
    "Label(win,bg='#f5e4ef',text=\"Tips to tame stress:\",font=('Aerial 20 bold italic')).pack(pady=10)\n",
    "\n",
    "def create_label(text):\n",
    "    label = tk.Label(win,bg='#f5e4ef', text=text, wraplength=1100, justify=\"center\",font=('Helvetica 12 bold',15))\n",
    "    label.pack(pady=10)\n",
    "\n",
    "#canvas= Canvas(win, width= 1500, height= 750)\n",
    "create_label(\"Breaaatheeee!: Take slow, deep breaths to lower heart rate and blood pressure.\")\n",
    "create_label(\"Take a quick walk: When you’re feeling overwhelmed go for a quick stroll. You’ll get the benefits of alone time, physical activity, and a few minutes to gather your thoughts.\")\n",
    "create_label(\"Count Backward!: When worries are running rampant, try slowly counting to 10 and then back again to calm down.\")\n",
    "create_label(\"Stretch: Stand up for a quick stretch to relieve muscle tension which helps you relax.\")\n",
    "#create_label(\"Write it down buddy: Putting our emotions on paper can make them seem less intimidating, hence try journaling to calm your nerves.\")\n",
    "#create_label(\"Talk to a Friend: When something’s really bothering you, it can help to share your feelings with a buddy. Vent it out!!\")\n",
    "\n",
    "\n",
    "\n",
    "#canvas.pack()\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8980674a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\JOY' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy==1.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f30359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\JOY' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.16.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab177f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db73365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
